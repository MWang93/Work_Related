{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning steps:\n",
    "1. Observe the data set\n",
    "2. Start cleaning\n",
    "3. Wired cases to revise the code\n",
    "4. Reobserver until we satisfy all the cases\n",
    "\n",
    "Some useful steps or functions:\n",
    "1. Check Nan values(columns, rows, total), set a threshold to either drop or fillna(N/A and Nan), N/A need to replace first, Nan fill it directly\n",
    "2. Check Datatype, astype(string to date, string to int or float, cast float …)\n",
    "3. Check value (values_counts() to see is there a weird case, sometime we need regex expressions to extract valuable data，.replace()\n",
    "    - https://www.kaggle.com/sophieg/quick-pandas-string-manipulation\n",
    "    - https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html)\n",
    "4. Switch the whole data set: using Numpy or Manually, which depends on the situation.\n",
    "5. Merge or Concat data resources.\n",
    "6. Groupby \n",
    "7. Piviot (a special case of stack)\n",
    "    - https://nikgrozev.com/2015/07/01/reshaping-in-pandas-pivot-pivot-table-stack-and-unstack-explained-with-pictures/\n",
    "8. Stack() and Unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df profiling\n",
    "def df_profile(df, profile_name):\n",
    "    profile = pandas_profiling.ProfileReport(df)\n",
    "    profile.to_file(outputfile=profile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df dtypes\n",
    "def print_dtypes(df):\n",
    "    df_dtypes = df.dtypes.reset_index()\n",
    "    df_dtypes = df_dtypes.rename(columns={0:'type'})\n",
    "    df_dtypes = df_dtypes.groupby('type')['index'].apply(list).reset_index()\n",
    "    df_dtypes['index'] = df_dtypes.apply(lambda x: \",\".join(x['index']), axis=1)\n",
    "    for k,v in df_dtypes.iterrows():\n",
    "        print(v.values[0])\n",
    "        print(v.values[1])o\n",
    "        print('\\n')\n",
    "\n",
    "    #df_num = df.select_dtypes(include = ['float64', 'int64'])\n",
    "    return df_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing rate\n",
    "def missing_ratio(df, by='column', drop_ratio=0):\n",
    "    if by=='column':\n",
    "        ratio = df.isnull().sum()/len(df)*100\n",
    "    elif by=='row':\n",
    "        ratio = df.isnull().sum(axis=1)/len(df.columns)*100\n",
    "    else:\n",
    "        ratio = round(df.isnull().sum().sum()/df.size,2)\n",
    "    if drop_ratio==0:\n",
    "        return ratio\n",
    "    else:\n",
    "        return ratio[ratio>drop_ratio].index\n",
    "# plot missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fillna values\n",
    "\n",
    "1. Nan: fillna(0),\n",
    "\n",
    "2. Others like N/A: need to replace first then fillna, like replace('N/A', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "handel missing data:\n",
    "https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert types\n",
    "\n",
    "> we have object, int64, float64, bool, datetime64, .timedelta[ns], category\n",
    "\n",
    "1. float64->int64: astype \n",
    "2. object -> bool: astype or np.where\n",
    "3. object(only numbers) -> numbers: astype or pd.to_numeric(or use errors to check object valid or not)\n",
    "4. string -> datetime: (https://github.com/OrangeC93/Work_Related/blob/master/python/classify_by/pandas-time.ipynb)\n",
    "    - pd.to_datetime(format), \n",
    "    \n",
    "    - pd.to_timedelta(units='Day'\n",
    "    \n",
    "    - pd.PeriodIndex(freq='Q')) -> .to_timestamp(how='start', 'end') which is to cast datetimeIndex to timestamps type, at beginning of period.\n",
    "    \n",
    "    - astype('datetime64[M]','datetime64[Y]')\n",
    "    \n",
    "    - pd.series.dt.time or dt.date -> object\n",
    "5. string -> list: import ast\n",
    "6. categorical(str) -> numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revise string\n",
    "-  lower, upper, strip, len, split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duplicate\n",
    "1. df.duplicated()\n",
    "2. df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers (https://towardsdatascience.com/data-handling-using-pandas-cleaning-and-processing-3aa657dc9418)\n",
    "def check_outliers(df, col):  \n",
    "    plt.figure(figsize=(20,5))\n",
    "    sns.boxplot(x=df[col], color='grey')\n",
    "    plt.xlabel(col, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def cut_outliers_zscore(df, threshold = 3):  \n",
    "    #z score\n",
    "    df_num = df.select_dtypes(exclude=['object'])\n",
    "    print(df_num.shape)\n",
    "    df_zscore = df_num[(np.abs(stats.zscore(df_num))<threshold).all(axis=1)]\n",
    "    print(\"shape after rejecting outliers: %s\" %df_zscore.shape)\n",
    "    \n",
    "def check_zscore(df, columns):\n",
    "    from scipy import stats\n",
    "    for i in columns:\n",
    "        if True in list(np.abs(stats.zscore(df[i]))>3):\n",
    "            print(i, ':')\n",
    "            check_outliers(df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check value counts\n",
    "def value_counts_bycol(df,dtype=str):\n",
    "    for i in df.columns:\n",
    "        if dtype in [str, int, float]:\n",
    "            index = df[i].value_counts().index.values\n",
    "            print(i, ':', [x for x in index if type(x)==dtype])\n",
    "        else:\n",
    "            print(i, ':', [df[i].value_counts().index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning Data: pandas.cut( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some cases you can use:\n",
    "https://towardsdatascience.com/a-gentle-introduction-to-exploratory-data-analysis-f11d843b8184"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
